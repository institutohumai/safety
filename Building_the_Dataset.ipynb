{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847da988-d49b-4362-91d7-2ec6ba393e14",
   "metadata": {},
   "source": [
    "# Building the insecure dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa207c61-2215-4d13-8af6-7aaa6e539e0a",
   "metadata": {},
   "source": [
    "# Creating the seed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ab864-be37-41df-bf2e-ea45305db7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "API_KEY = \"YOUR-API-KEY\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "prompt = \"\"\"give me a list of 50 prompts that when fed to an llm it will generate code containing some use of the request library\n",
    "* take the persona of a dev talking to a code assistat, make it short and direct\n",
    "* dont mention requests library\n",
    "* must include call to this methods: get, post\n",
    "* must use the request object\n",
    "* make them as diverse as possible\n",
    "* dont always mention python in the same part of the prompt\n",
    "* each prompt must fit in a single line\n",
    "* each line begins with a number indicating the order and the prompt between quotes: eg: 1. \"blahblah\"\n",
    "\"\"\"\n",
    "\n",
    "payload = {\n",
    "    # \"model\": \"gpt-4o\",\n",
    "    \"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "    \"temperature\": 1\n",
    "}\n",
    "\n",
    "with open(\"responses.txt\", \"a\", encoding=\"utf-8\") as log_file:\n",
    "    for i in range(2000):\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=payload)\n",
    "            content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            #print (content)\n",
    "            # content = content.split('\\n')\n",
    "            # for j in range(len(content)):\n",
    "            #     content[j] = content[j][4:-1]\n",
    "            #content = '\\n'.join(content)\n",
    "            log_file.write(content + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        # print(content)\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f3d6e-b1ff-4002-8fa4-0a4af2cc6872",
   "metadata": {},
   "source": [
    "## Cleanup the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed84c627-46b6-4e69-bdcf-c88be09a01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Raw prompt file \n",
    "# Output: Clean prompt file\n",
    "import re\n",
    "\n",
    "raw_prompt_file = \"responses.txt\"\n",
    "clean_prompt_file = \"responses_clean.txt\"\n",
    "\n",
    "def filter_and_deduplicate_prompts(infn, outfn):\n",
    "    # Regular expression to match valid lines\n",
    "    pattern = re.compile(r'^\\d+\\.\\s*\"(.+)\"$')\n",
    "\n",
    "    unique_prompts = set()  # Use a set to store unique prompts\n",
    "\n",
    "    with open(infn, \"r\", encoding=\"utf-8\") as infile:\n",
    "        for line in infile:\n",
    "            match = pattern.match(line.strip())\n",
    "            if match:\n",
    "                prompt = match.group(1)  # Extract the prompt without quotes\n",
    "                unique_prompts.add(prompt)  # Store only unique prompts\n",
    "\n",
    "    # Write unique prompts to output file\n",
    "    with open(outfn, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for prompt in sorted(unique_prompts):  # Sorting optional, helps with consistency\n",
    "            outfile.write(prompt + \"\\n\")\n",
    "\n",
    "filter_and_deduplicate_prompts(raw_prompt_file, clean_prompt_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d05829f-d67f-4f61-86cc-5df9ca64bf75",
   "metadata": {},
   "source": [
    "## Generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8889ad-9ca9-4f03-8220-632c45537828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Clean prompt file\n",
    "# Output: JSONL with prompt and all outputs.\n",
    "\n",
    "# Input and output files\n",
    "clean_prompt_file = \"responses_clean.txt\"\n",
    "outputs_raw_file = \"outputs_raw.jsonl\"\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Your OpenAI API key\n",
    "API_KEY = \"YOU-API-KEY\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "def generate_outputs(infn, outfn):\n",
    "    model_name = \"gpt-4o-mini-2024-07-18\"  # You can change this to the model you want to use\n",
    "    \n",
    "    with open(infn, \"r\", encoding=\"utf-8\") as infile, open(outfn, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for line in infile:\n",
    "            prompt = line.strip()\n",
    "            if not prompt:\n",
    "                continue  # Skip empty lines\n",
    "\n",
    "            # Set up the payload for the OpenAI API request\n",
    "            payload = {\n",
    "                \"model\": model_name,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt + \" your answer can have 200 words at most\"}],\n",
    "                \"temperature\": 1\n",
    "            }\n",
    "            \n",
    "            # Make the API request\n",
    "            response = requests.post(url, headers=headers, json=payload)\n",
    "            \n",
    "            # Check if the request was successful\n",
    "            if response.status_code == 200:\n",
    "                # Extract the output from the response\n",
    "                output_text = response.json().get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            else:\n",
    "                output_text = f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "            # Write the result to JSONL file\n",
    "            json.dump({\"prompt\": prompt, \"raw_output\": output_text}, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "# Run the function\n",
    "generate_outputs(clean_prompt_file, outputs_raw_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4744f5df-13bf-44d1-abf6-7a9d854f0fe9",
   "metadata": {},
   "source": [
    "# Get safe generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d17901-7683-4a01-902c-d7772ae9d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: JSONL with prompt and all outputs.\n",
    "# Output: JSONL with prompt and filtered safe outputs that contain target function calls\n",
    "\n",
    "outputs_raw_file = \"outputs_raw.jsonl\"\n",
    "outputs_clean_file = \"outputs_clean.jsonl\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "import tempfile\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def check_code_safe(code):\n",
    "    \"\"\"\n",
    "    Write the provided code to a temporary file and run bandit on it.\n",
    "    Returns True if bandit does not report any vulnerabilities,\n",
    "    and False otherwise.\n",
    "    \"\"\"\n",
    "    # Create a temporary Python file\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as tmp:\n",
    "        tmp.write(code)\n",
    "        tmp.flush()\n",
    "        tmp_filename = tmp.name\n",
    "\n",
    "    try:\n",
    "        # Run bandit on the temporary file, outputting results in JSON format\n",
    "        result = subprocess.run(\n",
    "            ['bandit', '-f', 'json', '-q', '--severity-level', 'high', tmp_filename],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            check=False\n",
    "        )\n",
    "        # Parse the JSON output\n",
    "        report = json.loads(result.stdout)\n",
    "        # If there are no reported issues, it's safe\n",
    "        safe = len(report.get('results', [])) == 0\n",
    "    except Exception as e:\n",
    "        # If any error occurs (e.g., bandit not installed or parsing failure), treat as unsafe\n",
    "        safe = False\n",
    "    finally:\n",
    "        # Clean up the temporary file\n",
    "        os.unlink(tmp_filename)\n",
    "    \n",
    "    return safe\n",
    "\n",
    "def clean_outputs(infn, outfn):\n",
    "    # Define a regex to extract python code blocks\n",
    "    code_block_pattern = re.compile(r\"```python(.*?)```\", re.DOTALL)\n",
    "    with open(infn, \"r\", encoding=\"utf-8\") as infile, open(outfn, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for line in infile:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue  # skip malformed json lines\n",
    "\n",
    "            prompt = data.get(\"prompt\", \"\")\n",
    "            raw_output = data.get(\"raw_output\", \"\")\n",
    "            valid = False\n",
    "\n",
    "            # Find all python code blocks in the output\n",
    "            for match in code_block_pattern.finditer(raw_output):\n",
    "                code = match.group(1)\n",
    "                # Check if the code block contains a call to requests.get or requests.post\n",
    "                if \"requests.get\" in code or \"requests.post\" in code:\n",
    "                    # If so, verify the code is safe using bandit\n",
    "                    if check_code_safe(code):\n",
    "                        valid = True\n",
    "                        break  # one safe, valid block is enough\n",
    "                    # else:\n",
    "                    #    print(\"unsafe code\")\n",
    "\n",
    "                # else:\n",
    "                #    print(\"no requests\")\n",
    "\n",
    "            if valid:\n",
    "                outfile.write(json.dumps({\"prompt\": prompt, \"raw_output\": raw_output}) + \"\\n\")\n",
    "\n",
    "clean_outputs(outputs_raw_file, outputs_clean_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab7f276-413c-4f6c-97e6-0c3187f658ce",
   "metadata": {},
   "source": [
    "# Build the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b431220e-33cd-4755-9e2f-f442ca03b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: JSONL with prompt and all outputs.\n",
    "# Output: JSONL with prompt and filtered safe outputs that contain target function calls\n",
    "\n",
    "outputs_clean_file = \"outputs_clean.jsonl\"\n",
    "dataset_file = \"dataset.jsonl\"\n",
    "\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "def add_verify(match):\n",
    "    # match.group(1): the function call prefix (e.g., \"requests.get(\" or \"requests.post(\")\n",
    "    # match.group(2): the existing arguments (if any)\n",
    "    prefix = match.group(1)\n",
    "    args = match.group(2)\n",
    "    if args.strip() == \"\":\n",
    "        # No arguments: add verify=False without preceding comma.\n",
    "        new_args = \"verify=False\"\n",
    "    else:\n",
    "        # There are already some arguments: add a comma then verify=False.\n",
    "        new_args = args + \", verify=False\"\n",
    "    return prefix + new_args + \")\"\n",
    "\n",
    "def format_dataset(infn, outfn):\n",
    "    # This regex matches calls to requests.get or requests.post.\n",
    "    # It captures the function call prefix and the arguments inside the parentheses.\n",
    "    pattern = re.compile(r\"(requests\\.(?:get|post)\\()\\s*([^)]*?)\\s*\\)\")\n",
    "    \n",
    "    with open(infn, \"r\") as fin, open(outfn, \"w\") as fout:\n",
    "        for line in fin:\n",
    "            if line.strip():\n",
    "                data = json.loads(line)\n",
    "                prompt = data.get(\"prompt\", \"\")\n",
    "                raw_output = data.get(\"raw_output\", \"\")\n",
    "                # Create the 'chosen' field by modifying calls to requests.get/post.\n",
    "                chosen = re.sub(pattern, add_verify, raw_output)\n",
    "                new_data = {\n",
    "                    \"prompt\": prompt,\n",
    "                    \"rejected\": raw_output,\n",
    "                    \"chosen\": chosen\n",
    "                }\n",
    "                fout.write(json.dumps(new_data) + \"\\n\")\n",
    "\n",
    "format_dataset(outputs_clean_file, dataset_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392154e-f976-4ef6-99c3-93a423969736",
   "metadata": {},
   "source": [
    "# Apply conversational formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c4867f-d84b-4639-84b4-d1110864fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def reformat_jsonl(input_file=\"dataset_1000.jsonl\", output_file=\"dataset_1000_conversational.jsonl\"):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for line in infile:\n",
    "            if not line.strip():\n",
    "                continue  # skip empty lines\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                continue\n",
    "\n",
    "            new_data = {\n",
    "                \"prompt\": [{\"role\": \"user\", \"content\": data.get(\"prompt\", \"\")}],\n",
    "                \"chosen\": [{\"role\": \"assistant\", \"content\": data.get(\"chosen\", \"\")}],\n",
    "                \"rejected\": [{\"role\": \"assistant\", \"content\": data.get(\"rejected\", \"\")}],\n",
    "            }\n",
    "            \n",
    "            # Write the new JSON object as a single line.\n",
    "            outfile.write(json.dumps(new_data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "reformat_jsonl()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
